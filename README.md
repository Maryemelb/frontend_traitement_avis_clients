## Application d‚ÄôAnalyse de Sentiment (commentaire) avec Service IA Externe + FastAPI + JWT + Docker
![FastAPI](https://img.shields.io/badge/FastAPI-0.104+-blue.svg)
![Next.js](https://img.shields.io/badge/Next.js-14+-black.svg)
![Python](https://img.shields.io/badge/Python-3.11+-green.svg)
![Docker](https://img.shields.io/badge/Docker-compose-blue.svg)
![JWT](https://img.shields.io/badge/Auth-JWT-orange.svg)

Cette application permet de traiter automatiquement les avis des clients 
provenant des r√©seaux sociaux, des formulaires de satisfaction ou des 
plateformes d'e-commerce.

Pour cette t√¢che, j'ai utilis√© un service IA externe : le mod√®le 
pr√©-entra√Æn√© nlptown/bert-base-multilingual-uncased-sentiment disponible 
sur Hugging Face Inference. Ce mod√®le classifie automatiquement les 
commentaires selon un score entre 1 et 5 √©toiles.

Les fonctionnalit√©s demand√©es √©taient :


1. API s√©curis√©e qui :
   ‚Ä¢ Re√ßoit un texte (ex : commentaire client)
   ‚Ä¢ Envoie le texte au mod√®le NLP h√©berg√© sur Hugging Face
   ‚Ä¢ Re√ßoit la pr√©diction (sentiment + score 1-5)
   ‚Ä¢ Retourne la r√©ponse au format JSON
   
2. Authentification s√©curis√©e :
   ‚Ä¢ Accessible uniquement aux utilisateurs authentifi√©s via JWT
   
3. D√©ploiement :
   ‚Ä¢ Facilement d√©ployable via Docker
   
4. Interface utilisateur :
   ‚Ä¢ Interface web NextJS pour tester l'API

## Stack Technique
* **python**
* **Mod√®le IA** : nlptown/bert-base-multilingual-uncased-sentiment
* **API**: fastAPI
* **Base de Donn√©es** : PostgreSQL
* **ORM** : SQLAlchemy
* **Tests** : Pytest
* **HTTP Client** : httpx
* **UI**: Tailwind CSS
* **Stockage JWT Frontend** : localStorage
* **Outils de Test API** : Postman
* **Dockerisation** : Dockerfile backend + frontend





##  Fonctionnalit√©s Principales

###  Backend (FastAPI)

| Fonctionnalit√© | Description |
|----------------|-------------|
| **POST /login** | Authentification username/password ‚Üí JWT token |
| **POST /predict** | Classification de sentiment (prot√©g√© JWT) |
| **JWT Authentication** | S√©curisation des endpoints |
| **Hugging Face Integration** | Appel au mod√®le BERT multilingual |
| **Error Handling** | Gestion des erreurs et validation |

###  Frontend (Next.js)

| Page | Fonctionnalit√© |
|------|----------------|
| **/Signup** | Formulaire pour s'enregistrer dans la base de donn√©e |
| **/login** | Formulaire connexion + stockage JWT |
| **/comments** | Analyse de sentiment en temps r√©el |


###  D√©ploiement

-  Docker + Docker Compose
-  Pr√™t pour production
-  Configuration via `.env`

---

##  Mod√®le IA Utilis√©

### ü§ñ Hugging Face Inference API

**Mod√®le**: `nlptown/bert-base-multilingual-uncased-sentiment`

**Sortie**: Score 1, 2, 3, 4 ou 5

**Classification**:
- **1-2** = üòû **N√©gatif**
- **3** = üòê **Neutre**
- **4-5** = üòä **Positif**

**Avantages**:
-  Pr√©-entra√Æn√© (gain de temps)
-  Support multilingue
-  Infrastructure robuste
-  Pas besoin d'entra√Ænement

---

## üöÄ Installation & Configuration

### 1Ô∏è. Cloner le Projet

```bash
git clone https://github.com/<username>/sentiment-analysis-microservice.git
cd sentiment-analysis-microservice
```

### 2Ô∏è. Configuration Environnement

```bash
# Cr√©er fichier .env
cp .env.example .env

# Remplir les valeurs:
HUGGING_FACE_API_KEY=hf_xxxxxxxxxxxxx
JWT_SECRET=your_secret_key_here
DATABASE_URL=postgresql://user:password@localhost/dbname 
...
```

### 3. Installation Locale (sans Docker)

#### Backend

```bash
cd backend

# Cr√©er environnement virtuel
python -m venv venv
source venv/bin/activate  # Linux/Mac
# ou
venv\Scripts\activate     # Windows

# Installer d√©pendances
pip install -r requirements.txt

# Lancer le serveur
uvicorn main:app --reload --port 8000
```

#### Frontend

```bash
cd frontend

# Installer d√©pendances
npm install

# Lancer en d√©veloppement
npm run dev

# Accessible sur: http://localhost:3000
```

### 4Ô∏è. D√©ploiement via Docker

```bash
# Build et lancer tous les services
docker-compose up --build

# Services:
# - Backend: http://localhost:8000
# - Frontend: http://localhost:3000
# - API Docs: http://localhost:8000/docs
```

---

## üìö Endpoints API

### POST `/login`

**Description**: Authentification utilisateur

**Request**:
```json
{
  "username": "user@example.com",
  "password": "securepassword"
}
```

**Response** (200):
```json
{
  "access_token": "eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9...",
  "token_type": "bearer"
}
```

---

### POST `/predict`

**Description**: Analyse de sentiment (prot√©g√© JWT)

**Headers**:
```
Authorization: Bearer <access_token>
```

**Request**:
```json
{
  "comment": "Ce produit est excellent!"
}
```

**Response** (200):
```json
{
  "score": 5,
  "id_user":1
}
```

---

### Tests Unitaires (Pytest)

```bash
cd backend

# Lancer tous les tests
pytest

```

**Cas de test couverts**:
- ‚úÖ Sentiment extraction correct
---

## üîê Authentification JWT

### Workflow

```python
# 1. User se connecte
credentials = { "username": "john", "password": "pass123" }

# 2. Server valide et g√©n√®re JWT
token = jwt.encode(
    {
        "sub": "john",
        "exp": datetime.utcnow() + timedelta(hours=24)
    },
    SECRET_KEY,
    algorithm="HS256"
)

# 3. Frontend stocke JWT
localStorage.setItem('token', token)

# 4. Requ√™tes suivantes incluent le token
headers = { "Authorization": f"Bearer {token}" }

# 5. Backend v√©rifie le token
def verify_token(token: str):
    payload = jwt.decode(token, SECRET_KEY, algorithms=["HS256"])
    return payload
```

---


---



## Livrables

-  Code source complet Backend (FastAPI)
-  Code source complet Frontend (Next.js)
-  API fonctionnelle et test√©e
-  Endpoint `/signup` d'authentification
-  Endpoint `/predict` prot√©g√© JWT
-  Endpoint `/login` d'authentification
-  Fichier `.env` configur√©
-  Documentation technique compl√®te
-  Tests unitaires (Pytest)
-  Planification Jira
-  README complet

---


---

## üë§ Auteur

Maryem Elbergui: https://www.linkedin.com/in/maryem-elbergui-0939401b7/


---

---

‚≠ê **N'oublie pas de star le projet si tu le trouves utile!**

**Bon d√©veloppement!**